---
editor_options:
  markdown:
    wrap: 72
---

# Answers {.unnumbered}

*Section 5 Practical: Building Multidimensional Confirmatory Factor Analysis Models*

Let's load the required packages: 


```r
library(lavaan)
library(tidyverse)
```

And import the data. 


```r
whitehall <- read_csv("data/whitehall_NA.csv")
```

## Task 1 {-}

*Fit a two-factor model of the "mental health" items, ("nervous", "down", "peace", "sad", "happy"). One factor is to be indicated by the positive items ("happy", "peace"), and one factor indicated by the negative items ("nervous", "down", "sad")*.


Let's construct the two-factor model whereby:  

`neg =~ sad + nervous + down` is the negative mood  
`pos =~ happy + peace` is the positive mood   
`pos ~~ neg` is the factor correlation  


```r
mh_fac2 <- 'neg =~ sad + nervous + down   
            pos =~ happy + peace         
            pos ~~ neg '                  
```


Now let's fit the model to the obtain and have a look at the results. 


```r
fit_mh_fac2 <- cfa(mh_fac2, data = whitehall, meanstructure = TRUE)

summary(fit_mh_fac2, fit.measures = TRUE, standardized = TRUE)
```

```
## lavaan 0.6-18 ended normally after 24 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        16
## 
##                                                   Used       Total
##   Number of observations                          8288       10308
## 
## Model Test User Model:
##                                                       
##   Test statistic                               200.351
##   Degrees of freedom                                 4
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                             13261.213
##   Degrees of freedom                                10
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.985
##   Tucker-Lewis Index (TLI)                       0.963
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -52661.626
##   Loglikelihood unrestricted model (H1)     -52561.450
##                                                       
##   Akaike (AIC)                              105355.252
##   Bayesian (BIC)                            105467.613
##   Sample-size adjusted Bayesian (SABIC)     105416.768
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.077
##   90 Percent confidence interval - lower         0.068
##   90 Percent confidence interval - upper         0.086
##   P-value H_0: RMSEA <= 0.050                    0.000
##   P-value H_0: RMSEA >= 0.080                    0.303
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.020
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   neg =~                                                                
##     sad               1.000                               0.792    0.847
##     nervous           0.713    0.015   47.897    0.000    0.564    0.571
##     down              0.775    0.013   59.175    0.000    0.614    0.737
##   pos =~                                                                
##     happy             1.000                               0.936    0.829
##     peace             0.926    0.019   47.694    0.000    0.867    0.716
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   neg ~~                                                                
##     pos              -0.511    0.013  -40.378    0.000   -0.690   -0.690
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               1.872    0.010  182.334    0.000    1.872    2.003
##    .nervous           1.725    0.011  159.095    0.000    1.725    1.748
##    .down              1.433    0.009  156.627    0.000    1.433    1.720
##    .happy             4.265    0.012  344.279    0.000    4.265    3.782
##    .peace             3.752    0.013  282.320    0.000    3.752    3.101
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               0.247    0.009   27.504    0.000    0.247    0.282
##    .nervous           0.657    0.011   57.380    0.000    0.657    0.673
##    .down              0.317    0.007   44.885    0.000    0.317    0.457
##    .happy             0.397    0.017   23.512    0.000    0.397    0.312
##    .peace             0.713    0.017   40.846    0.000    0.713    0.487
##     neg               0.627    0.015   40.875    0.000    1.000    1.000
##     pos               0.875    0.024   35.749    0.000    1.000    1.000
```

To obtain further information, we can use the `LavResiduals()` function. 


```r
lavResiduals(fit_mh_fac2)
```

```
## $type
## [1] "cor.bentler"
## 
## $cov
##            sad nervos   down  happy  peace
## sad      0.000                            
## nervous -0.026  0.000                     
## down     0.002  0.040  0.000              
## happy   -0.019  0.004  0.033  0.000       
## peace   -0.014 -0.043  0.048  0.000  0.000
## 
## $mean
##     sad nervous    down   happy   peace 
##       0       0       0       0       0 
## 
## $cov.z
##             sad  nervos    down   happy   peace
## sad       0.000                                
## nervous -12.370   0.000                        
## down      2.381   9.235   0.000                
## happy    -8.171   0.579   8.564   0.000        
## peace    -5.085  -6.139  10.900   0.000   0.000
## 
## $mean.z
##     sad nervous    down   happy   peace 
##       0       0       0       0       0 
## 
## $summary
##                             cov mean   total
## srmr                      0.023 0.00   0.020
## srmr.se                   0.001   NA   0.001
## srmr.exactfit.z          15.720   NA  15.720
## srmr.exactfit.pvalue      0.000   NA   0.000
## usrmr                     0.023 0.00   0.020
## usrmr.se                  0.002   NA   0.001
## usrmr.ci.lower            0.020   NA   0.018
## usrmr.ci.upper            0.026   NA   0.022
## usrmr.closefit.h0.value   0.050 0.05   0.050
## usrmr.closefit.z        -16.347   NA -21.052
## usrmr.closefit.pvalue     1.000   NA   1.000
```

### Question 1: What makes this a good model? {-}

The CFI of 0.985 indicates close fit. The SRMR of $0.02$ indicates close fit. The `std.all` loadings for all but one items are good ($>0.7$).  The correlation between the factors ($-0.69$) is negative, as expected, and not so large as to suggest a single factor

### Question 2: What makes this a bad model? {-}

The RMSEA of $0.077$ is above $0.05$, indicating some misfit. The model chi-square of $200.351$ is much lower than for the unidimensional model, but is still significant. The `std.all` loading for one item (**nervous**) is weak ($0.57$). There are still some non-trivial residuals for some items (e.g. **peace**)

### Question 3: Compare the two-factor model with a one-factor model using LRT {-}

First, we fit the one-factor model.


```r
mh_fac <- 'mh =~ nervous + down + peace + sad + happy'
fit_mh_fac <- cfa(mh_fac, data = whitehall, meanstructure = TRUE)
```

We then run the Likelihood Ratio Test of one- vs. two-factor models. 


```r
anova(fit_mh_fac, fit_mh_fac2)
```

```
## 
## Chi-Squared Difference Test
## 
##             Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    
## fit_mh_fac2  4 105355 105468  200.35                                          
## fit_mh_fac   5 106816 106921 1663.24     1462.9 0.41998       1  < 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

The LR Chi-square is $1462.9$, $df = 1$, $p < 0.001$. There is a strong significant difference in model fit (i.e. chi-square difference). The two-factor model is strongly preferred to the one-factor model 


## Task 2 {-}

*Fit a one-factor model of the "mental health" items, ("nervous", "down", "peace", "sad", "happy"), just like you did in the previous practical. However, in this model, allow the residual variances for the items happy and peace to correlate with each other.*

Let's fit the model and explore the results. 


```r
mh_fac_cor <- 'mh =~ nervous + down + peace + sad + happy
               # allow happy and peace to have a residual correlation
               happy ~~ peace
              '
fit_mh_fac_cor <- cfa(mh_fac_cor, data = whitehall, meanstructure = TRUE)

summary(fit_mh_fac_cor, fit.measures = TRUE, standardized = TRUE)
```

```
## lavaan 0.6-18 ended normally after 24 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        16
## 
##                                                   Used       Total
##   Number of observations                          8288       10308
## 
## Model Test User Model:
##                                                       
##   Test statistic                               200.351
##   Degrees of freedom                                 4
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                             13261.213
##   Degrees of freedom                                10
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.985
##   Tucker-Lewis Index (TLI)                       0.963
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -52661.626
##   Loglikelihood unrestricted model (H1)     -52561.450
##                                                       
##   Akaike (AIC)                              105355.252
##   Bayesian (BIC)                            105467.613
##   Sample-size adjusted Bayesian (SABIC)     105416.768
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.077
##   90 Percent confidence interval - lower         0.068
##   90 Percent confidence interval - upper         0.086
##   P-value H_0: RMSEA <= 0.050                    0.000
##   P-value H_0: RMSEA >= 0.080                    0.303
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.020
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   mh =~                                                                 
##     nervous           1.000                               0.564    0.571
##     down              1.088    0.023   46.722    0.000    0.614    0.737
##     peace            -1.060    0.030  -35.724    0.000   -0.598   -0.494
##     sad               1.403    0.029   47.897    0.000    0.792    0.847
##     happy            -1.144    0.029  -39.895    0.000   -0.646   -0.572
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##  .peace ~~                                                              
##    .happy             0.425    0.013   32.315    0.000    0.425    0.437
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .nervous           1.725    0.011  159.095    0.000    1.725    1.748
##    .down              1.433    0.009  156.627    0.000    1.433    1.720
##    .peace             3.752    0.013  282.320    0.000    3.752    3.101
##    .sad               1.872    0.010  182.334    0.000    1.872    2.003
##    .happy             4.265    0.012  344.279    0.000    4.265    3.782
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .nervous           0.657    0.011   57.380    0.000    0.657    0.673
##    .down              0.317    0.007   44.885    0.000    0.317    0.457
##    .peace             1.106    0.019   59.530    0.000    1.106    0.756
##    .sad               0.247    0.009   27.504    0.000    0.247    0.282
##    .happy             0.855    0.015   57.181    0.000    0.855    0.672
##     mh                0.318    0.012   25.800    0.000    1.000    1.000
```

The model fit indices are identical to the two-dimensional model! Allowing the residual variances of the positive items to correlate is doing the same thing that the two-factor model did - it's capturing the relationship between the positive items that the single factor could not capture on its own. In the two-factor model, this relationship was captured by the factor, here it's captured by the residual correlation. These are two different ways of modelling the same thing. These are equivalent models, that have the same number of model parameters and the same model fit.


## Task 3 {-}

*The bifactor model - fit a model with the following specifications:*   

-  *A general factor "mood" indicated by all five items;*    
-  *A specific factor "positive mood" indicated by the items "happy" and "peace";*      
-  *The correlation between the general and specific factors is fixed to zero.*  

Specifying the model whereby:  

`general =~ sad + nervous + down + happy + peace` is the general factor     
`pos     =~ happy + peace` is the specific positive factor  
`general ~~ 0*pos` is factor correlation = zero   


```r
mh_bifac <- 'general =~ sad + nervous + down + happy + peace
             pos     =~ happy + peace
             general ~~ 0*pos '                  
```

Fitting the model to the data and exploring the results.


```r
fit_mh_bifac <- cfa(mh_bifac, data = whitehall, meanstructure = TRUE)

summary(fit_mh_bifac, fit.measures = TRUE, standardized = TRUE)
```

```
## lavaan 0.6-18 ended normally after 20 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        17
## 
##                                                   Used       Total
##   Number of observations                          8288       10308
## 
## Model Test User Model:
##                                                       
##   Test statistic                               200.351
##   Degrees of freedom                                 3
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                             13261.213
##   Degrees of freedom                                10
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.985
##   Tucker-Lewis Index (TLI)                       0.950
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -52661.626
##   Loglikelihood unrestricted model (H1)     -52561.450
##                                                       
##   Akaike (AIC)                              105357.252
##   Bayesian (BIC)                            105476.635
##   Sample-size adjusted Bayesian (SABIC)     105422.612
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.089
##   90 Percent confidence interval - lower         0.079
##   90 Percent confidence interval - upper         0.100
##   P-value H_0: RMSEA <= 0.050                    0.000
##   P-value H_0: RMSEA >= 0.080                    0.929
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.020
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   general =~                                                            
##     sad               1.000                               0.792    0.847
##     nervous           0.713       NA                      0.564    0.571
##     down              0.775       NA                      0.614    0.737
##     happy            -0.815       NA                     -0.646   -0.572
##     peace            -0.755       NA                     -0.598   -0.494
##   pos =~                                                                
##     happy             1.000                               0.730    0.648
##     peace             0.796       NA                      0.581    0.481
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   general ~~                                                            
##     pos               0.000                               0.000    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               1.872       NA                      1.872    2.003
##    .nervous           1.725       NA                      1.725    1.748
##    .down              1.433       NA                      1.433    1.720
##    .happy             4.265       NA                      4.265    3.782
##    .peace             3.752       NA                      3.752    3.101
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               0.247       NA                      0.247    0.282
##    .nervous           0.657       NA                      0.657    0.673
##    .down              0.317       NA                      0.317    0.457
##    .happy             0.322       NA                      0.322    0.253
##    .peace             0.768       NA                      0.768    0.525
##     general           0.627       NA                      1.000    1.000
##     pos               0.534       NA                      1.000    1.000
```

### Question: How do you interpret the fit and coefficients of this model? {-}

The results look odd - there are no SEs for many parameters. The model looks identified, and the parameter estimates look sensible, so what might be going on? Perhaps the assumptions of the SEs have been violated. We can estimate the SEs using weaker assumptions - the bootstrap method. This is computationally intensive, so it may take a minute to estimate.


```r
fit_mh_bifac <- cfa(mh_bifac, data = whitehall, meanstructure = TRUE, se = "bootstrap")
summary(fit_mh_bifac, fit.measures = TRUE, standardized = TRUE)
```

```
## lavaan 0.6-18 ended normally after 20 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        17
## 
##                                                   Used       Total
##   Number of observations                          8288       10308
## 
## Model Test User Model:
##                                                       
##   Test statistic                               200.351
##   Degrees of freedom                                 3
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                             13261.213
##   Degrees of freedom                                10
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.985
##   Tucker-Lewis Index (TLI)                       0.950
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -52661.626
##   Loglikelihood unrestricted model (H1)     -52561.450
##                                                       
##   Akaike (AIC)                              105357.252
##   Bayesian (BIC)                            105476.635
##   Sample-size adjusted Bayesian (SABIC)     105422.612
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.089
##   90 Percent confidence interval - lower         0.079
##   90 Percent confidence interval - upper         0.100
##   P-value H_0: RMSEA <= 0.050                    0.000
##   P-value H_0: RMSEA >= 0.080                    0.929
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.020
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   general =~                                                            
##     sad               1.000                               0.792    0.847
##     nervous           0.713    0.022   32.350    0.000    0.564    0.571
##     down              0.775    0.015   50.107    0.000    0.614    0.737
##     happy            -0.815    0.023  -34.992    0.000   -0.646   -0.572
##     peace            -0.755    0.025  -30.534    0.000   -0.598   -0.494
##   pos =~                                                                
##     happy             1.000                               0.730    0.648
##     peace             0.796    0.012   67.921    0.000    0.581    0.481
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   general ~~                                                            
##     pos               0.000                               0.000    0.000
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               1.872    0.011  175.206    0.000    1.872    2.003
##    .nervous           1.725    0.011  155.451    0.000    1.725    1.748
##    .down              1.433    0.009  156.164    0.000    1.433    1.720
##    .happy             4.265    0.013  339.181    0.000    4.265    3.782
##    .peace             3.752    0.014  271.012    0.000    3.752    3.101
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               0.247    0.011   21.462    0.000    0.247    0.282
##    .nervous           0.657    0.018   37.030    0.000    0.657    0.673
##    .down              0.317    0.014   22.967    0.000    0.317    0.457
##    .happy             0.322    0.012   25.798    0.000    0.322    0.253
##    .peace             0.768    0.016   47.869    0.000    0.768    0.525
##     general           0.627    0.022   29.044    0.000    1.000    1.000
##     pos               0.534    0.017   31.991    0.000    1.000    1.000
```

Let's now compare it with the earlier two-factor model.


```r
summary(fit_mh_fac2, fit.measures = TRUE, standardized = TRUE)
```

```
## lavaan 0.6-18 ended normally after 24 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        16
## 
##                                                   Used       Total
##   Number of observations                          8288       10308
## 
## Model Test User Model:
##                                                       
##   Test statistic                               200.351
##   Degrees of freedom                                 4
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                             13261.213
##   Degrees of freedom                                10
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.985
##   Tucker-Lewis Index (TLI)                       0.963
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -52661.626
##   Loglikelihood unrestricted model (H1)     -52561.450
##                                                       
##   Akaike (AIC)                              105355.252
##   Bayesian (BIC)                            105467.613
##   Sample-size adjusted Bayesian (SABIC)     105416.768
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.077
##   90 Percent confidence interval - lower         0.068
##   90 Percent confidence interval - upper         0.086
##   P-value H_0: RMSEA <= 0.050                    0.000
##   P-value H_0: RMSEA >= 0.080                    0.303
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.020
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   neg =~                                                                
##     sad               1.000                               0.792    0.847
##     nervous           0.713    0.015   47.897    0.000    0.564    0.571
##     down              0.775    0.013   59.175    0.000    0.614    0.737
##   pos =~                                                                
##     happy             1.000                               0.936    0.829
##     peace             0.926    0.019   47.694    0.000    0.867    0.716
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##   neg ~~                                                                
##     pos              -0.511    0.013  -40.378    0.000   -0.690   -0.690
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               1.872    0.010  182.334    0.000    1.872    2.003
##    .nervous           1.725    0.011  159.095    0.000    1.725    1.748
##    .down              1.433    0.009  156.627    0.000    1.433    1.720
##    .happy             4.265    0.012  344.279    0.000    4.265    3.782
##    .peace             3.752    0.013  282.320    0.000    3.752    3.101
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
##    .sad               0.247    0.009   27.504    0.000    0.247    0.282
##    .nervous           0.657    0.011   57.380    0.000    0.657    0.673
##    .down              0.317    0.007   44.885    0.000    0.317    0.457
##    .happy             0.397    0.017   23.512    0.000    0.397    0.312
##    .peace             0.713    0.017   40.846    0.000    0.713    0.487
##     neg               0.627    0.015   40.875    0.000    1.000    1.000
##     pos               0.875    0.024   35.749    0.000    1.000    1.000
```

The chi-squre model fit is THE SAME ($200.351$), but because the bifactor model is slightly more complex (it has one extra parameter, so one fewer df), the RMSEA is a bit worse. In terms of the factor loadings, the standardized factor loadings for the general factor are good ($ > 0.7$) for sad and down, but fairly poor ($<0.6$) for the others. This suggests that these items do not really tap into a general mood factor very well. The standardized loadings for the pos factor are also weak, so the specific  factor is not really providing a good explanation for the positive items, either  after accounting for the general factor. Considering these bifactor results alongside the separate factors model, these are two different conceptual models. Both have similar fit, but the coefficients seem to support the two-factor model better, and the extra complexith of the  bifactor model isn't repaid by better model fit.

