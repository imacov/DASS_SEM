---
editor_options:
  markdown:
    wrap: 72
---

# Answers {.unnumbered}

*Section 5 Practical: Building Multidimensional Confirmatory Factor Analysis Models*


<script>
function revealContent() {
  var code = document.getElementById("codeInput").value;
  if (code === "DASS_S5_CFA_MultiD") {  
    document.getElementById("hiddenContent").style.display = "block";
  } else {
    alert("Incorrect code!");
  }
}
</script>

<p>Enter the code provided on Blackboard to view the answers:</p>
<input type="text" id="codeInput">
<button onclick="revealContent()">Submit</button>

<div id="hiddenContent" style="display:none;">


Let's load the required packages: 

```{r warning = FALSE, message = FALSE}
library(lavaan)
library(tidyverse)
```

And import the data. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
whitehall <- read_csv("D:/DASS/whitehall_NA.csv")
```


```{r eval = FALSE,  warning = FALSE, message = FALSE}
whitehall <- read_csv("data/whitehall_NA.csv")
```

## Task 1 {-}

*Fit a two-factor model of the "mental health" items, ("nervous", "down", "peace", "sad", "happy"). One factor is to be indicated by the positive items ("happy", "peace"), and one factor indicated by the negative items ("nervous", "down", "sad")*.


Let's construct the two-factor model whereby:  

`neg =~ sad + nervous + down` is the negative mood  
`pos =~ happy + peace` is the positive mood   
`pos ~~ neg` is the factor correlation  

```{r}
mh_fac2 <- 'neg =~ sad + nervous + down   
            pos =~ happy + peace         
            pos ~~ neg '                  
```


Now let's fit the model to the obtain and have a look at the results. 

```{r}
fit_mh_fac2 <- cfa(mh_fac2, data = whitehall, meanstructure = TRUE)

summary(fit_mh_fac2, fit.measures = TRUE, standardized = TRUE)
```

To obtain further information, we can use the `LavResiduals()` function. 

```{r}
lavResiduals(fit_mh_fac2)
```

### Question 1: What makes this a good model? {-}

The CFI of 0.985 indicates close fit. The SRMR of $0.02$ indicates close fit. The `std.all` loadings for all but one items are good ($>0.7$).  The correlation between the factors ($-0.69$) is negative, as expected, and not so large as to suggest a single factor

### Question 2: What makes this a bad model? {-}

The RMSEA of $0.077$ is above $0.05$, indicating some misfit. The model chi-square of $200.351$ is much lower than for the unidimensional model, but is still significant. The `std.all` loading for one item (**nervous**) is weak ($0.57$). There are still some non-trivial residuals for some items (e.g. **peace**)

### Question 3: Compare the two-factor model with a one-factor model using LRT {-}

First, we fit the one-factor model.

```{r}
mh_fac <- 'mh =~ nervous + down + peace + sad + happy'
fit_mh_fac <- cfa(mh_fac, data = whitehall, meanstructure = TRUE)
```

We then run the Likelihood Ratio Test of one- vs. two-factor models. 

```{r}
anova(fit_mh_fac, fit_mh_fac2)
```

The LR Chi-square is $1462.9$, $df = 1$, $p < 0.001$. There is a strong significant difference in model fit (i.e. chi-square difference). The two-factor model is strongly preferred to the one-factor model 


## Task 2 {-}

*Fit a one-factor model of the "mental health" items, ("nervous", "down", "peace", "sad", "happy"), just like you did in the previous practical. However, in this model, allow the residual variances for the items happy and peace to correlate with each other.*

Let's fit the model and explore the results. 

```{r}
mh_fac_cor <- 'mh =~ nervous + down + peace + sad + happy
               # allow happy and peace to have a residual correlation
               happy ~~ peace
              '
fit_mh_fac_cor <- cfa(mh_fac_cor, data = whitehall, meanstructure = TRUE)

summary(fit_mh_fac_cor, fit.measures = TRUE, standardized = TRUE)
```

The model fit indices are identical to the two-dimensional model! Allowing the residual variances of the positive items to correlate is doing the same thing that the two-factor model did - it's capturing the relationship between the positive items that the single factor could not capture on its own. In the two-factor model, this relationship was captured by the factor, here it's captured by the residual correlation. These are two different ways of modelling the same thing. These are equivalent models, that have the same number of model parameters and the same model fit.


## Task 3 {-}

*The bifactor model - fit a model with the following specifications:*   

-  *A general factor "mood" indicated by all five items;*    
-  *A specific factor "positive mood" indicated by the items "happy" and "peace";*      
-  *The correlation between the general and specific factors is fixed to zero.*  

Specifying the model whereby:  

`general =~ sad + nervous + down + happy + peace` is the general factor     
`pos     =~ happy + peace` is the specific positive factor  
`general ~~ 0*pos` is factor correlation = zero   

```{r}
mh_bifac <- 'general =~ sad + nervous + down + happy + peace
             pos     =~ happy + peace
             general ~~ 0*pos '                  
```

Fitting the model to the data and exploring the results.

```{r warning = FALSE, message = FALSE}

fit_mh_bifac <- cfa(mh_bifac, data = whitehall, meanstructure = TRUE)

summary(fit_mh_bifac, fit.measures = TRUE, standardized = TRUE)
```

### Question: How do you interpret the fit and coefficients of this model? {-}

The results look odd - there are no SEs for many parameters. The model looks identified, and the parameter estimates look sensible, so what might be going on? Perhaps the assumptions of the SEs have been violated. We can estimate the SEs using weaker assumptions - the bootstrap method. This is computationally intensive, so it may take a minute to estimate.

```{r}
fit_mh_bifac <- cfa(mh_bifac, data = whitehall, meanstructure = TRUE, se = "bootstrap")
summary(fit_mh_bifac, fit.measures = TRUE, standardized = TRUE)
```

Let's now compare it with the earlier two-factor model.

```{r}
summary(fit_mh_fac2, fit.measures = TRUE, standardized = TRUE)
```

The chi-squre model fit is THE SAME ($200.351$), but because the bifactor model is slightly more complex (it has one extra parameter, so one fewer df), the RMSEA is a bit worse. In terms of the factor loadings, the standardized factor loadings for the general factor are good ($ > 0.7$) for sad and down, but fairly poor ($<0.6$) for the others. This suggests that these items do not really tap into a general mood factor very well. The standardized loadings for the pos factor are also weak, so the specific  factor is not really providing a good explanation for the positive items, either  after accounting for the general factor. Considering these bifactor results alongside the separate factors model, these are two different conceptual models. Both have similar fit, but the coefficients seem to support the two-factor model better, and the extra complexith of the  bifactor model isn't repaid by better model fit.

